{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gc\n",
    "from scipy.sparse import coo_matrix, lil_matrix, csr_matrix, load_npz\n",
    "from multiprocessing import Pool\n",
    "from time import time\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "import os\n",
    "import io\n",
    "import distutils.dir_util\n",
    "import json\n",
    "import pickle5 as pickle\n",
    "\n",
    "\n",
    "def pickle_load(fname):\n",
    "    with open(fname, 'rb') as handle:\n",
    "        data = pickle.load(handle)\n",
    "    return data\n",
    "\n",
    "def write_json(data, fname):\n",
    "    def _conv(o):\n",
    "        if isinstance(o, (np.int64, np.int32)):\n",
    "            return int(o)\n",
    "        raise TypeError\n",
    "\n",
    "    parent = os.path.dirname(fname)\n",
    "    distutils.dir_util.mkpath(\"./\" + parent)\n",
    "    with io.open(\"./\" + fname, \"w\", encoding=\"utf-8\") as f:\n",
    "        json_str = json.dumps(data, ensure_ascii=False, default=_conv)\n",
    "        f.write(json_str)\n",
    "\n",
    "def load_json(fname):\n",
    "    with open(fname, encoding=\"utf-8\") as f:\n",
    "        json_obj = json.load(f)\n",
    "\n",
    "    return json_obj\n",
    "\n",
    "def remove_seen(seen, l):\n",
    "    seen = set(seen)\n",
    "    return [x for x in l if not (x in seen)]\n",
    "\n",
    "def neighbor_based_cf(playlist_id):\n",
    "    item_indices = test_item_indices[playlist_id]\n",
    "\n",
    "    alpha, beta, theta = 0.9, 0.7, 0.99\n",
    "    Cr = 0.4 + (100 - np.shape(item_indices)[0]) * 0.0055\n",
    "    if Cr < 0.2:\n",
    "        Cr = 0.2\n",
    "    elif Cr > 1:\n",
    "        Cr = 1\n",
    "    \n",
    "    song_playlist_train_matrix = lil_matrix(song_playlist_train_matrix_raw)\n",
    "    song_playlist_train_matrix[:,p_encode[playlist_id]] = 0\n",
    "\n",
    "    weight = song_playlist_train_matrix[item_indices, :].multiply(np.power(1e-1 + I_list, beta - 1)).sum(axis=0)\n",
    "    weight = np.array(weight).flatten()\n",
    "    weight = np.power(weight,theta)\n",
    "    value = song_playlist_train_matrix[item_indices, :].multiply(weight)\n",
    "    value = value.dot(song_playlist_train_matrix.transpose()) \n",
    "    I_song_i = np.power(1e-1+I_song[item_indices],-alpha)\n",
    "    value = value.multiply(I_song_i.reshape((-1,1)))\n",
    "    value = value.multiply(np.power(1e-1+I_song,alpha-1))\n",
    "    value = csr_matrix(value)\n",
    "\n",
    "    predictions = lil_matrix(value)\n",
    "    label = np.zeros(song_playlist_train_matrix.shape[0])\n",
    "    label[item_indices] = 1\n",
    "    \n",
    "    clf = LinearSVC(C=Cr,class_weight={0:1,1:1},tol=1e-6, dual = True, max_iter=360000)\n",
    "    clf.fit(predictions.transpose(),label)\n",
    "    predictions = clf.decision_function(predictions.transpose())\n",
    "    predictions = np.argsort(np.array(predictions).flatten() - min(predictions))[::-1]\n",
    "\n",
    "    return np.array(list(predictions[predictions < tag_start_idx][:400]) + list(predictions[(predictions >= tag_start_idx) & (predictions < tag_title_start_idx)][:100]))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load train matrix...\n"
     ]
    }
   ],
   "source": [
    "s_decode = pickle_load('data/song_label_decoder.pickle')\n",
    "p_encode = pickle_load('data/playlist_label_encoder.pickle')\n",
    "tag_start_idx = s_decode['@tag_start_idx']\n",
    "tag_title_start_idx = s_decode['@tag_title_start_idx']\n",
    "\n",
    "print(\"load train matrix...\")\n",
    "playlist_song_train_matrix = load_npz('data/playlist_song_train_matrix.npz')\n",
    "song_playlist_train_matrix_raw = lil_matrix(playlist_song_train_matrix.transpose())\n",
    "\n",
    "gc.collect()                                                                                                                                                                                              \n",
    "\n",
    "I_song = np.array(song_playlist_train_matrix_raw.sum(axis=1)).flatten()\n",
    "I_list = np.array(song_playlist_train_matrix_raw.sum(axis=0)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load test data...\n"
     ]
    }
   ],
   "source": [
    "print(\"load test data...\")\n",
    "test = load_json('data/test_items.json')\n",
    "test_item_indices = dict()\n",
    "test_playlist_id = []\n",
    "for q in test:\n",
    "    if 'items' in q.keys():\n",
    "        test_item_indices[q['id']] = q['items']\n",
    "        test_playlist_id.append(q['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22852"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_playlist_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions begin...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 688/22852 [1:42:52<106:50:34, 17.35s/it]c:\\Users\\SV\\anaconda3\\envs\\final_cf\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "100%|██████████| 22852/22852 [66:41:07<00:00, 10.51s/it]      \n",
      "100%|██████████| 22852/22852 [00:04<00:00, 5437.32it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"predictions begin...\")\n",
    "\n",
    "results = []  # 결과를 저장할 빈 리스트를 생성합니다.\n",
    "\n",
    "for playlist_id in tqdm(test_playlist_id):\n",
    "    result = neighbor_based_cf(playlist_id)\n",
    "    results.append(result)\n",
    "\n",
    "prediction_results = {}\n",
    "for i in tqdm(range(len(results))):\n",
    "    prediction_results[test_playlist_id[i]] = {\"songs\": [s_decode[s] for s in results[i][:400]], \"tags\": [s_decode[s] for s in results[i][400:]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('prediction_results.json','w') as f:\n",
    "  json.dump(prediction_results, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write results.json...\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "print(\"write results.json...\")\n",
    "answers = []\n",
    "for q in test:\n",
    "    if q['id'] in test_playlist_id:\n",
    "        answers.append({'id': q['id'],\n",
    "        'songs': remove_seen(q['songs'], prediction_results[q['id']]['songs'])[:100],\n",
    "        'tags': remove_seen(q['tags'], prediction_results[q['id']]['tags'])[:10] })\n",
    "    else:\n",
    "        answers.append({'id': q['id'],\n",
    "        'songs': remove_seen(q['songs'], q['songs_mp'])[:100],\n",
    "        'tags': remove_seen(q['tags'], q['tags_mp'])[:10] })\n",
    "    if len(answers[len(answers)-1]['songs']) < 100 or len(answers[len(answers)-1]['tags']) < 10:\n",
    "        answers[len(answers)-1]['songs'] = (answers[len(answers)-1]['songs'] + remove_seen(q['songs'] + answers[len(answers)-1]['songs'], q['songs_mp']))[:100]\n",
    "        answers[len(answers)-1]['tags'] = (answers[len(answers)-1]['tags'] + remove_seen(q['tags'] + answers[len(answers)-1]['tags'], q['tags_mp']))[:10]\n",
    "write_json(answers, 'results.json')\n",
    "\n",
    "print('end')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final_cf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
